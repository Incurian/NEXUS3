{
  "default_model": "fast",
  "providers": {
    "openrouter": {
      "type": "openrouter",
      "api_key_env": "OPENROUTER_API_KEY",
      "base_url": "https://openrouter.ai/api/v1",
      "models": {
        "gemini": {
          "id": "google/gemini-3-flash-preview",
          "context_window": 1048576,
          "guidance": "Google Gemini. Good for: large context tasks, multimodal. Use as general purpose model."
        },
        "gpt": {
          "id": "openai/gpt-5.2",
          "context_window": 400000,
          "reasoning": false,
          "guidance": "OpenAI GPT-5.2 with extended thinking. Good for: deep analysis, validation, complex reasoning. This is our go-to architect and reviewer."
        },
        "oss": {
          "id": "openai/gpt-oss-120b",
          "context_window": 131072,
          "guidance": "Open-source model. Good for: budget tasks, experimentation, smoke tests."
        },
        "fast": {
          "id": "x-ai/grok-4.1-fast",
          "context_window": 2000000,
          "guidance": "Huge 2M context and very fast. Good for: research, reading many files. Sometimes has issues with tool use and coding."
        }
      }
    },
    "anthropic": {
      "type": "anthropic",
      "api_key_env": "ANTHROPIC_API_KEY",
      "base_url": "https://api.anthropic.com",
      "auth_method": "x-api-key",
      "models": {
        "haiku-native": {
          "id": "claude-haiku-4-5",
          "context_window": 200000,
          "guidance": "Fast Claude. Good for: quick tasks, summarization, simple edits."
        },
        "sonnet-native": {
          "id": "claude-sonnet-4-5",
          "context_window": 200000,
          "guidance": "Balanced Claude. Good for: most coding, analysis, writing. Default Claude."
        },
        "opus-native": {
          "id": "claude-opus-4-5",
          "context_window": 200000,
          "guidance": "Most capable Claude. Good for: complex reasoning, architecture. Expensive."
        }
      }
    },
    "onprem-example-selfsigned": {
      "type": "openai",
      "base_url": "https://llm.internal.company.com/v1",
      "api_key_env": "ONPREM_API_KEY",
      "verify_ssl": false,
      "models": {
        "onprem": {
          "id": "llama-3-70b",
          "context_window": 8192,
          "guidance": "EXAMPLE: On-prem with self-signed cert. Set verify_ssl=false. Modify base_url, api_key_env, and model id for your setup."
        }
      }
    },
    "onprem-example-corporate-ca": {
      "type": "openai",
      "base_url": "https://llm.internal.company.com/v1",
      "api_key_env": "ONPREM_API_KEY",
      "ssl_ca_cert": "/etc/ssl/certs/corporate-ca.crt",
      "models": {
        "onprem-ca": {
          "id": "llama-3-70b",
          "context_window": 8192,
          "guidance": "EXAMPLE: On-prem with corporate CA. More secure than verify_ssl=false. Modify ssl_ca_cert path for your CA."
        }
      }
    }
  },
  "stream_output": true,
  "max_tool_iterations": 100,
  "default_permission_level": "trusted",
  "skill_timeout": 120.0,
  "max_concurrent_tools": 10,
  "compaction": {
    "enabled": true,
    "model": "fast",
    "summary_budget_ratio": 0.25,
    "recent_preserve_ratio": 0.25,
    "trigger_threshold": 0.9
  },
  "mcp_servers": [
    {
      "name": "test",
      "command": ["python3", "-m", "nexus3.mcp.test_server"]
    },
    {
      "name": "http-test",
      "url": "http://127.0.0.1:9000"
    }
  ],
  "context": {
    "include_readme": false,
    "readme_as_fallback": false
  }
}
